<!DOCTYPE html>
<html>
<head>
  <title> Notes on minimum spanning trees | ICS 311 Spring 2014 </title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta charset="utf-8">
  <link rel="stylesheet" href="http://netdna.bootstrapcdn.com/bootswatch/3.1.0/cerulean/bootstrap.min.css">

  <!--  Load site-specific customizations after bootstrap. -->
  <link rel="stylesheet" href="/ics311s14/css/style.css">
  <link rel="stylesheet" href="/ics311s14/css/syntax.css">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open+Sans:normal,italic,bold">
  <link rel="shortcut icon" href="/ics311s14/favicon.ico" type="image/x-icon" />

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
  <script src="http://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.6.2/html5shiv.js"></script>
  <script src="http://cdnjs.cloudflare.com/ajax/libs/respond.js/1.2.0/respond.js"></script>
  <![endif]-->

  <!-- Load Bootstrap JavaScript components -->
  <script src="http://code.jquery.com/jquery.min.js"></script>
  <script src="http://netdna.bootstrapcdn.com/bootstrap/3.1.0/js/bootstrap.min.js"></script>
</head>
<body>
<!-- Responsive navbar -->
<div class="navbar navbar-default navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <!--  Display three horizontal lines when navbar collapsed. -->
        <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="#"> ICS 311 Spring 2014 </a>
    </div>
    <div class="collapse navbar-collapse">
      <ul class="nav navbar-nav">
        <li><a href="/ics311s14/index.html">Home</a></li>
        <li><a href="/ics311s14/modules/">Modules</a></li>
        <li><a href="/ics311s14/outcomes/">Outcomes</a></li>
        <li><a href="/ics311s14/readings/">Readings</a></li>
        <li><a href="/ics311s14/experiences/">Experiences</a></li>
        <li><a href="/ics311s14/assessments/">Assessments</a></li>
        <li><a href="/ics311s14/schedule/">Schedule</a></li>
        
      </ul>
    </div>
  </div>
</div>


<div class="container">
  <h2>Outline</h2>

<ol>
<li>Minimum Spanning Trees </li>
<li>Generic Algorithm and Safe Edge Theorem </li>
<li>Kruskal&#39;s Algorithm </li>
<li>Prim&#39;s Algorithm </li>
</ol>

<h2>Minimum Spanning Trees</h2>

<h3>Spanning Trees</h3>

<p>A <strong>spanning tree</strong> <em>T</em> for a connected graph <em>G</em> is a tree that includes all
the vertices of <em>G</em>: it <em>spans</em> the graph.</p>

<p>Without calling them such, we have already encountered two kinds of spanning
trees in the introduction to graphs (<a href="http://www2.hawaii.edu/%7Esuthers/courses/ics311s14/Notes/Topic-14.html">Topic
14</a>):
those generated by breadth-first search and depth-first search. We saw that _
breadth-first trees _ are one way of finding shortest paths in a graph, and _
depth-first forests _ (a collection of spanning trees, one for each connected
component) are good for uncovering the structure of a graph such as
topological sort and connectivity. These were defined on unweighted graphs.</p>

<h3>Minimum Spanning Trees</h3>

<p>Many application areas (e.g., in communications, electronics, and
transportation) require finding the lowest cost way to connect a set of
objects or locations. For example, the cost may be measured in terms of
currency or distance. We can model such situations with <em><strong>weighted graphs</strong></em>,
introduced in <a href="http://www2.hawaii.edu/%7Esuthers/courses/ics311s14/Notes/Topic-14.html">Topic
14</a> as
graphs where a real-valued number is associated with each edge. Then we want
to find a spanning tree of minimum cost.</p>

<p>More formally, we can pose this as a problem on a graph representation <em>G</em> =
(<em>V</em>, <em>E</em>):</p>

<ul>
<li>The objects or locations are vertices <em>V</em> and the available connections are edges <em>E</em>.</li>
<li>A weight function <em>w</em>(<em>u</em>,<em>v</em>) gives the weight on each edge (<em>u</em>,<em>v</em>) ∈ <em>E</em>.</li>
<li>We seek <em>T</em> ⊆ <em>E</em> such that 

<ul>
<li><em>T</em> connects all the vertices <em>V</em> of <em>G</em>. </li>
<li>The sum of weights <em>w</em>(<em>T</em>) = Σ(<em>u</em>,<em>v</em>)∈<em>T</em> <em>w</em>(<em>u</em>,<em>v</em>) is minimized. </li>
</ul></li>
</ul>

<p>A few facts can be noted:</p>

<ul>
<li><em>G</em> must be connected (consist of a single connected component) in order for <em>T</em> to be possible. </li>
<li>However, if <em>G</em> is not connected we can generalize the problem to one of finding <em>T</em>1 ... <em>Tc</em> for each of <em>c</em> connected components of <em>G</em>.</li>
<li>A subgraph of <em>G</em> that connects its vertices <em>V</em> at minimal cost will always be a tree. <em>Why?</em></li>
</ul>

<p>Therefore we call this the <strong>minimum spanning tree (MST)</strong> problem (and the
generalized version the minimum spanning forest problem).</p>

<p>Here is an example of a minimum spanning tree (the shaded edges represent
<em>T</em>):</p>

<p><img src="fig/example-MST-1.jpg" alt=""></p>

<p><em>Are minimum spanning trees unique?</em></p>

<p>Look at edges (<em>e</em>,<em>f</em>) and (<em>c</em>,<em>e</em>).</p>

<hr>

<h2>Generic Algorithm and Safe Edge Theorem</h2>

<p>We specify a generic greedy algorithm for solving the MST problem. The
algorithm will be &quot;greedy&quot; in terms of always choosing a lowest cost edge.
This algorithm is instantiated into two versions, Kruskal&#39;s and Prim&#39;s
algorithms, which differ in how they define from what set of edges the lowest
cost edge is chosen.</p>

<p>Let&#39;s start by noting some properties that MSTs of <em>G</em> = (<em>V</em>, <em>E</em>) must have</p>

<ul>
<li>A MST for <em>G</em> has |<em>V</em>| − 1 edges. (See properties of trees, <a href="http://www2.hawaii.edu/%7Esuthers/courses/ics311s14/Notes/Topic-08.html">Topic 8</a>.)</li>
<li>Any tree (and hence any MST) has no cycles. It has only one path between any two vertices.</li>
<li>There might be more than one MST for <em>G</em>.</li>
</ul>

<h3>Building a Solution</h3>

<ul>
<li>We will build a set of edges <em>A</em>. </li>
<li>Initially <em>A</em> has no edges.</li>
<li>As we add edges to <em>A</em>, we maintain a loop invariant: <em>A</em> is a subset of <em>some</em> MST for <em>G</em>.</li>
</ul>

<p>Define an edge (<em>u</em>,<em>v</em>) to be <strong>safe</strong> for <em>A</em> iff <em>A</em> ∪ {(<em>u</em>,<em>v</em>)} is also
a subset of some MST for <em>G</em>.</p>

<p>(BTW, &quot;iff&quot; is not a spelling error: it is shorthand for &quot;if and only if&quot;
commonly used in proofs.</p>

<p>If we only add safe edges to <em>A</em>, once |<em>V</em>| − 1 edges have been added we have
a MST for <em>G</em>. This motivates the ...</p>

<h3>Generic MST Algorithm</h3>

<p><img src="fig/pseudocode-generic-MST.jpg" alt=""></p>

<p><em>Loop Invariant:</em> <em>A</em> is a subset of some MST for <em>G</em></p>

<ul>
<li><em>Initialization:</em> The initially empty set trivially satisfies the loop invariant.</li>
<li><em>Maintenance:</em> Since we add only safe edges, <em>A</em> remains a subset of some MST.</li>
<li><em>Termination:</em> We stop when <em>A</em> is a spanning tree (|<em>A</em>| = |<em>V</em>| − 1), and it is a subset of itself.</li>
</ul>

<p>OK, great, but how do we find safe edges?</p>

<h3>Finding Safe Edges</h3>

<p>Each time we add an edge we are connecting two sets of vertices that were not
previously connected by <em>A</em>. (Otherwise we would be forming a cycle.) A greedy
algorithm might try to keep the cost down by choosing the lowest cost edge
that connects previously unconnected vertices. (Perhaps we should call it a
&quot;stingy&quot; algorithm!)</p>

<p>But is this greedy strategy &quot;safe&quot;? How do we know that after adding this edge
we still have a subset of an MST?</p>

<p>First some definitions:</p>

<ul>
<li>A <strong>cut</strong> (<em>S</em>, <em>V</em> − <em>S</em>) is a partition of vertices into disjoint sets <em>S</em> and <em>V</em> − <em>S</em>. </li>
<li>Edge (<em>u</em>,<em>v</em>) ∈ <em>E</em> <strong>crosses</strong> cut (<em>S</em>, <em>V</em> − <em>S</em>) if one endpoint is in <em>S</em> and the other is in <em>V</em> − <em>S</em>. </li>
<li>A cut <strong>respects</strong> <em>A</em> iff no edge in <em>A</em> crosses the cut.</li>
<li>An edge is a <strong>light edge</strong> crossing a cut iff its weight is minimum over all edges crossing the cut. (There may be more than one light edge for a given cut.) </li>
</ul>

<p>The following illustrates a cut and will be used in the proof below. There are
two sets of vertices <em>S</em> and <em>V</em> − <em>S</em>. Four edges cross the cut (<em>S</em>, <em>V</em> -
<em>S</em>). Whether or not this respects <em>A</em> depends on what is in <em>A</em>.</p>

<p><img src="fig/illustration-safe-edge-theorem.jpg" alt=""></p>

<p><em>Suppose A is the shaded edges. Does this cut respect A?</em></p>

<h4>Safe Edge Theorem</h4>

<p>Let <em>G</em> = (<em>V</em>, <em>E</em>) be a graph, <em>A</em> be a subset of some MST for <em>G</em>, (<em>S</em>,
<em>V</em> − <em>S</em>) be a cut that respects <em>A</em>, and (<em>u</em>,<em>v</em>) be a light edge crossing
(<em>S</em>, <em>V</em> − <em>S</em>). Then (<em>u</em>,<em>v</em>) is safe for <em>A</em>.</p>

<p>(<em>A light edge that crosses a cut that respects _A</em> is safe for <em>A</em>._)</p>

<p><em><strong>Proof:</strong></em> Let <em>T</em> be a MST that includes <em>A</em>. Consider two cases:</p>

<p>Case 1: <em>T</em> contains (<em>u</em>,<em>v</em>). Then the theorem is proven, since <em>A</em> ∪
{(<em>u</em>,<em>v</em>)} ⊆ <em>T</em> is a subset of some MST for <em>G</em>.</p>

<p>Case 2: <em>T</em> does not contain (<em>u</em>,<em>v</em>). We will show that we can construct a
tree <em>T&#39;</em> that is a MST for <em>G</em> and that contains <em>A</em> ∪ {(<em>u</em>,<em>v</em>)}.</p>

<p><img src="fig/illustration-safe-edge-theorem.jpg" alt=""></p>

<p>Since <em>T</em> is a tree it contains a unique path <em>p</em> between <em>u</em> and <em>v</em>. Path
<em>p</em> must cross the cut (<em>S</em>, <em>V</em> − <em>S</em>) at least once (otherwise <em>T</em> would be
disconnected). Let (<em>x</em>,<em>y</em>) be an edge of <em>p</em> that crosses the cut.</p>

<p>(Except for the dashed edge (<em>u</em>,<em>v</em>), all the edges shown in the figure are
in <em>T</em>. <em>A</em> is not shown in the figure, but it cannot contain any edges that
cross the cut, since the cut respects <em>A</em>. Shaded edges are the path <em>p</em>.)</p>

<p>Since the cut respects <em>A</em>, edge (<em>x</em>,<em>y</em>) is not in <em>A</em>.</p>

<p>To form <em>T&#39;</em> from <em>T</em>: Remove (<em>x</em>,<em>y</em>). This breaks <em>T</em> into two components.
Add (<em>u</em>,<em>v</em>). This reconnects the tree. So <em>T&#39;</em> = T - {(<em>x</em>,<em>y</em>)} ∪ (<em>u</em>,<em>v</em>)
is a spanning tree.</p>

<p>To show that <em>T&#39;</em> is a minimal spanning tree: <em>w</em>(<em>T&#39;</em>) = <em>w</em>(<em>T</em>) -
<em>w</em>(<em>x</em>,<em>y</em>) + <em>w</em>(<em>u</em>,<em>v</em>) ≤ <em>w</em>(<em>T</em>) since (<em>u</em>,<em>v</em>) is light.</p>

<p>We still need to show that (<em>u</em>,<em>v</em>) is safe for <em>A</em>. Since <em>A</em> ⊆ <em>T</em> and
(<em>x</em>,<em>y</em>) ∉ <em>A</em> then A ⊆ <em>T&#39;</em>. Therefore <em>A</em> ∪ {(<em>u</em>,<em>v</em>)} ⊆ <em>T&#39;</em>, a MST. ♦</p>

<h4>Further Observations</h4>

<p><em>A</em> is a forest containing connected components. Initially each component is a
single vertex. Any safe edge merges two of these components into one. Each
component so constructed is a tree. Since an MST has exactly |<em>V</em>| − 1 edges,
the loop iterates |<em>V</em>| − 1 times before we are down to one component.</p>

<h4>Corollary</h4>

<p>If <em>C</em> = (<em>VC</em>, <em>EC</em>) is a connected component in the forest <em>GA</em> = (<em>V</em>, <em>A</em>)
and (<em>u</em>,<em>v</em>) is a light edge connecting <em>C</em> to some other component <em>C&#39;</em> in
<em>GA</em> -- that is, (<em>u</em>,<em>v</em>) is a light edge crossing the cut (<em>VC</em>, <em>V</em> -
<em>VC</em>) -- then (<em>u</em>,<em>v</em>) is safe for <em>A</em>.</p>

<p><em>Proof:</em> Set <em>S</em> = <em>VC</em> in the theorem. ♦</p>

<p>This idea (of thinking in terms of components rather than vertices) leads to
Kruskal&#39;s algorithm ...</p>

<hr>

<h2>Kruskal&#39;s Algorithm</h2>

<p>Kruskal&#39;s algorithm starts with each vertex being its own component, and
repeatedly merges two components into one by choosing the light edge that
connects them. It does this greedily (or stingily?) by scanning the edges in
increasing order by weight. A disjoint-set data structure is used to determine
whether an edge connects vertices in two different components.</p>

<p>This algorithm has similarities with the connected components algorithm we
previously saw in <a href="http://www2.hawaii.edu/%7Esuthers/courses/ics311s14/Notes/Topic-16.html">Topic
16</a>:</p>

<p><img src="fig/pseudocode-connected-components.jpg" alt=""></p>

<p>Here is Kruskal&#39;s version:</p>

<p><img src="fig/pseudocode-Kruskal-MST.jpg" alt=""></p>

<h3>Example</h3>

<p>Let&#39;s start with this example. The first edge has been chosen.</p>

<p><img src="fig/Fig-23-4-Kruskal-Example-a.jpg" alt=""></p>

<p>Add 4 more edges (notice we could add edges of weight 2 in either order, and
similarly for 4) ...</p>

<p><img src="fig/Fig-23-4-Kruskal-Example-e.jpg" alt=""></p>

<p>The next edge considered is not added because it would connect already
connected vertices:</p>

<p><a href="http://www2.hawaii.edu/%7E%0Asuthers/courses/ics311s14/Notes/Topic-17/Topic-17-K.html"> <img src="fig/Fig-23-4-Kruskal-Example-f.jpg" alt=""></a></p>

<p>Keep going until the MST is constructed, and click to see the final tree.</p>

<h3>Analysis</h3>

<p><img src="fig/pseudocode-Kruskal-MST.jpg" alt=""></p>

<p>The costs are:</p>

<ul>
<li>Initialize <em>A</em>: O(1)</li>
<li>First <code>for</code> loop: |<em>V</em>| <code>MAKE-SET</code> operations</li>
<li>Sort <em>E</em>: O(<em>E</em> lg <em>E</em>) </li>
<li>Second <code>for</code> loop: O(<em>E</em>) <code>FIND-SETs</code> and <code>UNIONs</code></li>
</ul>

<p>If we use the tree implementation of the disjoint-set data structure with
union by rank and path compression (<a href="http://www2.hawaii.edu/%7Esuthers/courses/ics311s14/Notes/Topic-16.html">Topic
16</a>),
the amortized cost per <code>MAKE-SET</code>, <code>UNION</code> and <code>FIND-SET</code> operation (across
|<em>E</em>| operations) is O(α(<em>V</em>)), where α is a <em>very</em> slowly growing function,
the inverse of Ackermann&#39;s function. (Lemma 21.11 states that MAKE-SET in
isolation is O(1), but here we must treat it as O(α(<em>V</em>)) since we are making
a statement about the amortized cost per operation in a <em>sequence</em> of <em>m</em>
operations: see section 24.1. Also, using O(α(<em>V</em>)) simplifies the expression
below.)</p>

<p>Droping the lower order O(1) and substituting α(<em>V</em>) for the disjoint-set
operations, the above list of costs sums to O((<em>V</em> + <em>E</em>)⋅α(<em>V</em>))+ O(<em>E</em> lg
<em>E</em>).</p>

<p>Since G is connected, |<em>E</em>| ≥ |<em>V</em>| − 1, so we can replace <em>V</em> with <em>E</em> to
simplify the first term for the disjoint-set operations, O((<em>V</em> +
<em>E</em>)⋅α(<em>V</em>)), to O((<em>E</em> + <em>E</em>)⋅α(<em>V</em>)) or O(<em>E</em>⋅α(<em>V</em>)).</p>

<p>Furthermore, α(<em>V</em>) = O(lg <em>V</em>) = O(lg <em>E</em>), so O(<em>E</em>⋅α(<em>V</em>)) is O(<em>E</em> lg
<em>E</em>), and hence the entire expression we started with, O((<em>V</em> + <em>E</em>)⋅α(<em>V</em>))+
O(<em>E</em> lg <em>E</em>), simplifies to O(<em>E</em> lg <em>E</em>).</p>

<p>Finally, since |<em>E</em>| ≤ |<em>V</em>|2, lg |<em>E</em>| = O(2 lg <em>V</em>) = O(lg <em>V</em>), so we can
write the result as <strong>O(<em>E</em> lg <em>V</em>)</strong> to obtain the growth rate in terms of
both |<em>E</em>| and |<em>V</em>|.</p>

<p>(It is usually a good idea to include both <em>V</em> and <em>E</em> when giving growth
rates for graph algorithms, unless one of them can be strictly limited to the
other. Shortly we will see that O(<em>E</em> lg <em>V</em>) enables comparison to Prim&#39;s
algorithm.)</p>

<hr>

<h2>Prim&#39;s Algorithm</h2>

<p>This algorithm is also a greedy (stingy) algorithm, but it builds one tree,
choosing the lightest edge incident on the growing tree, so the set <em>A</em> is
always a tree. The tree is initialized to be a single vertex, designated <em>r</em>
for root.</p>

<p>At each step it finds a light edge crossing the cut (<em>VA</em>, <em>V</em> - <em>VA</em>), where
<em>VA</em>= vertices that are incident on <em>A</em>, and adds this edge to <em>A</em>.
(Initially, <em>A</em> = {} and <em>VA</em> = {<em>r</em>}.)</p>

<p><img src="fig/illustration-Prims-algorithm.jpg" alt=""></p>

<p>(Edges of <em>A</em> are shaded in the illustration.)</p>

<h3>General Idea</h3>

<p>To find the light edge quickly we use a priority queue <em>Q</em> (<a href="http://www2.hawaii.edu/%7Esuthers/courses/ics311s14/Notes/Topic-09.html">Topic
09</a>):</p>

<ul>
<li>Each queued object is a vertex in <em>V</em> − <em>VA</em> (the vertices that have not yet been connected to <em>A</em>). </li>
<li>The key is the minimum weight of any edge (<em>u</em>,<em>v</em>) where <em>u</em> ∈ <em>VA</em>. (We update this weight for <em>v</em> whenever a new edge is found that reaches <em>v</em> at a lower cost than before.) </li>
<li>Thus the vertex returned by <code>EXTRACT-MIN</code> is for <em>v</em> such that ∃ <em>u</em> ∈ <em>VA</em> and (<em>u</em>,<em>v</em>) is a light edge crossing (<em>VA</em>, <em>V</em> - <em>VA</em>). </li>
<li>If <em>v</em> is not adjacent to any vertices in <em>VA</em>, the key of <em>v</em> is ∞</li>
</ul>

<p>The edges of <em>A</em> will form a rooted tree with root <em>r</em>, given as input (<em>r</em>
can be any vertex).</p>

<ul>
<li>Each vertex keeps track of its parent by the attribute <em>v</em>.π = parent of <em>v</em>, or NIL if <em>v</em> = <em>r</em> or has no parent yet.</li>
<li>As the algorithm progresses, <em>A</em> = {(<em>v</em>, <em>v</em>.π) : <em>v</em> ∈ <em>V</em> - {<em>r</em>} − <em>Q</em>}. </li>
<li>At termination, <em>Q</em> is empty, so <em>A</em> is a MST.</li>
</ul>

<h3>Pseudocode</h3>

<p>This code <em>differs from the book&#39;s version</em> in having explicit calls to the
heap methods:</p>

<p><img src="fig/pseudocode-Prim-MST-improved.jpg" alt=""></p>

<p>Notice that it is possible for the last <code>if</code> to execute multiple times for a
given <em>v</em>. In other words, we may find an edge reaching vertex <em>v</em>, but before
we choose to use it (because other edges have lower key values), we find
another edge reaching <em>v</em> for lower cost (key value). <em>Watch for this
situation in the example below.</em></p>

<h3>Example</h3>

<p>Let&#39;s try it with this graph. The first three steps are shown. Every time a
vertex is dequed, it is colored black and the cost of all adjacent vertices
are updated as needed. For example, when <strong>a</strong> is dequeued, the cost of <strong>b</strong>
is updated from infinite to 4, and the cost of <strong>h</strong> is updated from infinite
to 8. Then when <strong>b</strong> is dequeued, its neighbors are updated and so on.</p>

<p><img src="fig/Fig-23-5-Prim-Example-a-d.jpg" alt=""></p>

<p>_Did you see where a vertex&#39;s key was lowered from one non-infinite value to
another? Which one? _</p>

<p><em>Now finish it and click on the image to see final solution.</em></p>

<p><img src="fig/pseudocode-Prim-MST-improved.jpg" alt=""></p>

<h3>Analysis</h3>

<p>Performance depends on the priority queue implementation. With a binary heap
implementation (<a href="http://www2.hawaii.edu/%7Esuthers/courses/ics311s14/Notes/Topic-09.html">Topic
09</a>),
the costs are:</p>

<ul>
<li>Initialize <em>Q</em> and iterate over |<em>V</em>| vertices in first <code>for</code> loop to insert in queue, each insert being O(lg <em>V</em>): O(<em>V</em> lg <em>V</em>) total.</li>
<li>Decrease key of r: O(lg <em>V</em>)</li>
<li>The <code>while</code> loop has |<em>V</em>| <code>EXTRACT-MIN</code> calls -&gt; O(<em>V</em> lg <em>V</em>)</li>
<li>By amortized analysis, the inner <code>for each</code> loop processes Θ(|<em>E</em>|) edges, O(<em>E</em>) of which result in O(lg <em>V</em>) <code>DECREASE-KEY</code> calls -&gt; O(<em>E</em> lg <em>V</em>)</li>
</ul>

<p>The sum of the dominating terms is O(<em>V</em> lg <em>V</em>) + O(<em>E</em> lg <em>V</em>).</p>

<p>If G is connected, |<em>E</em>| ≥ |<em>V</em>| − 1, so we can replace O(<em>V</em> lg <em>V</em>) with
O(<em>E</em> lg <em>V</em>), and the total is <strong>O(<em>E</em> lg <em>V</em>)</strong>.</p>

<p>This is asympotitically the same as Kruskal&#39;s algorithm. A faster
implementation of O(<em>E</em> + <em>V</em> lg <em>V</em>) is possible with Fibonacci Heaps, as
explained in the text.</p>

<hr>

<p>Dan Suthers Last modified: Thu Apr 3 12:36:42 HST 2014<br>
Images are from the instructor&#39;s material for Cormen et al. Introduction to
Algorithms, Third Edition.  </p>

</div>



<div class="dark-blue-background">
<footer>
  <div class="container page-footer">
    
      <p>Example Name | Example Department | Example University <br>
email@example.com<br></p>

    
    <p style="margin: 0">Powered by the <a style="color: white" href="http://morea-framework.github.io/">Morea Framework</a><br>
       Last update on: <span>2014-04-23 13:13:06 -1000</span></p>
  </div>
</footer>
</div>
</body>
</html>
